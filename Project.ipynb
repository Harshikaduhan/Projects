{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f2325155",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\harsh\\anaconda3\\Lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import warnings\n",
    "warnings.simplefilter('ignore')\n",
    "import matplotlib.pyplot as plt\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Convolution2D\n",
    "from keras.layers import MaxPooling2D\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Flatten\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow import keras\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7dbf36df",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "train = ImageDataGenerator(rescale = 1./255)\n",
    "test = ImageDataGenerator(rescale = 1./255)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d301fcbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.utils import img_to_array,array_to_img,load_img\n",
    "\n",
    "dataaug = ImageDataGenerator(\n",
    "        rotation_range=20,\n",
    "        width_shift_range=0.3,\n",
    "        height_shift_range=0.1,\n",
    "        zoom_range=0.5,\n",
    "        horizontal_flip=True,\n",
    "        vertical_flip=True,\n",
    "        fill_mode='nearest')\n",
    "\n",
    "img = load_img(\"/Users/harsh/OneDrive/Desktop/paddy/blast.jpg\")  \n",
    "pic = img_to_array(img) \n",
    "pic = pic.reshape((1,) + pic.shape)\n",
    "\n",
    "i = 0\n",
    "for x in dataaug.flow(pic, batch_size=1,\n",
    "                          save_to_dir='/Users/harsh/OneDrive/Desktop/paddy/test/blast', save_prefix='blast', save_format='jpeg'):\n",
    "    i += 1\n",
    "    if i > 50:\n",
    "        break  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "54c6f680",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.utils import img_to_array,array_to_img,load_img\n",
    "\n",
    "dataaug = ImageDataGenerator(\n",
    "        rotation_range=20,\n",
    "        width_shift_range=0.3,\n",
    "        height_shift_range=0.1,\n",
    "        zoom_range=0.5,\n",
    "        horizontal_flip=True,\n",
    "        vertical_flip=True,\n",
    "        fill_mode='nearest')\n",
    "\n",
    "img = load_img(\"/Users/harsh/OneDrive/Desktop/paddy/BLB.jpg\")  \n",
    "pic = img_to_array(img) \n",
    "pic = pic.reshape((1,) + pic.shape)\n",
    "\n",
    "i = 0\n",
    "for x in dataaug.flow(pic, batch_size=1,\n",
    "                          save_to_dir='/Users/harsh/OneDrive/Desktop/paddy/test/BLB', save_prefix='BLB', save_format='jpeg'):\n",
    "    i += 1\n",
    "    if i > 50:\n",
    "        break  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f7b88e72",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.utils import img_to_array,array_to_img,load_img\n",
    "\n",
    "dataaug = ImageDataGenerator(\n",
    "        rotation_range=20,\n",
    "        width_shift_range=0.3,\n",
    "        height_shift_range=0.1,\n",
    "        zoom_range=0.5,\n",
    "        horizontal_flip=True,\n",
    "        vertical_flip=True,\n",
    "        fill_mode='nearest')\n",
    "\n",
    "img = load_img(\"/Users/harsh/OneDrive/Desktop/paddy/brownleaf.jpg\")  \n",
    "pic = img_to_array(img) \n",
    "pic = pic.reshape((1,) + pic.shape)\n",
    "\n",
    "i = 0\n",
    "for x in dataaug.flow(pic, batch_size=1,\n",
    "                          save_to_dir='/Users/harsh/OneDrive/Desktop/paddy/test/brown leaf', save_prefix='brown leaf', save_format='jpeg'):\n",
    "    i += 1\n",
    "    if i > 50:\n",
    "        break  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "67f00048",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.utils import img_to_array,array_to_img,load_img\n",
    "\n",
    "dataaug = ImageDataGenerator(\n",
    "        rotation_range=20,\n",
    "        width_shift_range=0.3,\n",
    "        height_shift_range=0.1,\n",
    "        zoom_range=0.5,\n",
    "        horizontal_flip=True,\n",
    "        vertical_flip=True,\n",
    "        fill_mode='nearest')\n",
    "\n",
    "img = load_img(\"/Users/harsh/OneDrive/Desktop/paddy/sheath.jpg\")  \n",
    "pic = img_to_array(img) \n",
    "pic = pic.reshape((1,) + pic.shape)\n",
    "\n",
    "i = 0\n",
    "for x in dataaug.flow(pic, batch_size=1,\n",
    "                          save_to_dir='/Users/harsh/OneDrive/Desktop/paddy/test/sheath', save_prefix='sheath', save_format='jpeg'):\n",
    "    i += 1\n",
    "    if i > 50:\n",
    "        break  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e78e5cf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.utils import img_to_array,array_to_img,load_img\n",
    "\n",
    "dataaug = ImageDataGenerator(\n",
    "        rotation_range=20,\n",
    "        width_shift_range=0.3,\n",
    "        height_shift_range=0.1,\n",
    "        zoom_range=0.5,\n",
    "        horizontal_flip=True,\n",
    "        vertical_flip=True,\n",
    "        fill_mode='nearest')\n",
    "\n",
    "img = load_img('/Users/harsh/OneDrive/Desktop/paddy/blast.jpg')  \n",
    "pic = img_to_array(img) \n",
    "pic = pic.reshape((1,) + pic.shape)\n",
    "\n",
    "i = 0\n",
    "for x in dataaug.flow(pic, batch_size=1,\n",
    "                          save_to_dir='/Users/harsh/OneDrive/Desktop/paddy/train/blast', save_prefix='blast', save_format='jpeg'):\n",
    "    i += 1\n",
    "    if i > 250:\n",
    "        break  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8a301b31",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.utils import img_to_array,array_to_img,load_img\n",
    "\n",
    "dataaug = ImageDataGenerator(\n",
    "        rotation_range=20,\n",
    "        width_shift_range=0.3,\n",
    "        height_shift_range=0.1,\n",
    "        zoom_range=0.5,\n",
    "        horizontal_flip=True,\n",
    "        vertical_flip=True,\n",
    "        fill_mode='nearest')\n",
    "\n",
    "img = load_img('/Users/harsh/OneDrive/Desktop/paddy/BLB.jpg')  \n",
    "pic = img_to_array(img) \n",
    "pic = pic.reshape((1,) + pic.shape)\n",
    "\n",
    "i = 0\n",
    "for x in dataaug.flow(pic, batch_size=1,\n",
    "                          save_to_dir='/Users/harsh/OneDrive/Desktop/paddy/train/BLB', save_prefix='BLB', save_format='jpeg'):\n",
    "    i += 1\n",
    "    if i > 250:\n",
    "        break  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f271040b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.utils import img_to_array,array_to_img,load_img\n",
    "\n",
    "dataaug = ImageDataGenerator(\n",
    "        rotation_range=20,\n",
    "        width_shift_range=0.3,\n",
    "        height_shift_range=0.1,\n",
    "        zoom_range=0.5,\n",
    "        horizontal_flip=True,\n",
    "        vertical_flip=True,\n",
    "        fill_mode='nearest')\n",
    "\n",
    "img = load_img('/Users/harsh/OneDrive/Desktop/paddy/brownleaf.jpg')  \n",
    "pic = img_to_array(img) \n",
    "pic = pic.reshape((1,) + pic.shape)\n",
    "\n",
    "i = 0\n",
    "for x in dataaug.flow(pic, batch_size=1,\n",
    "                          save_to_dir='/Users/harsh/OneDrive/Desktop/paddy/train/brown leaf', save_prefix='brown leaf', save_format='jpeg'):\n",
    "    i += 1\n",
    "    if i > 250:\n",
    "        break  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "94802437",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.utils import img_to_array,array_to_img,load_img\n",
    "\n",
    "dataaug = ImageDataGenerator(\n",
    "        rotation_range=20,\n",
    "        width_shift_range=0.3,\n",
    "        height_shift_range=0.1,\n",
    "        zoom_range=0.5,\n",
    "        horizontal_flip=True,\n",
    "        vertical_flip=True,\n",
    "        fill_mode='nearest')\n",
    "\n",
    "img = load_img(\"/Users/harsh/OneDrive/Desktop/paddy/sheath.jpg\")  \n",
    "pic = img_to_array(img) \n",
    "pic = pic.reshape((1,) + pic.shape)\n",
    "\n",
    "i = 0\n",
    "for x in dataaug.flow(pic, batch_size=1,\n",
    "                          save_to_dir='/Users/harsh/OneDrive/Desktop/paddy/train/sheath', save_prefix='sheath', save_format='jpeg'):\n",
    "    i += 1\n",
    "    if i > 250:\n",
    "        break  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b89c6306",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 2902 images belonging to 4 classes.\n",
      "Found 609 images belonging to 4 classes.\n"
     ]
    }
   ],
   "source": [
    "train_data = train.flow_from_directory('/Users/harsh/OneDrive/Desktop/paddy/train',\n",
    "                                                 target_size = (100, 100),\n",
    "                                                 class_mode = 'categorical')\n",
    "\n",
    "test_data = test.flow_from_directory('/Users/harsh/OneDrive/Desktop/paddy/test',\n",
    "                                            target_size = (100, 100),\n",
    "                                            class_mode = 'categorical')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "50abee55",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\harsh\\anaconda3\\Lib\\site-packages\\keras\\src\\backend.py:873: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\harsh\\anaconda3\\Lib\\site-packages\\keras\\src\\layers\\pooling\\max_pooling2d.py:161: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\harsh\\anaconda3\\Lib\\site-packages\\keras\\src\\optimizers\\__init__.py:309: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n",
      "Epoch 1/25\n",
      "WARNING:tensorflow:From C:\\Users\\harsh\\anaconda3\\Lib\\site-packages\\keras\\src\\utils\\tf_utils.py:492: The name tf.ragged.RaggedTensorValue is deprecated. Please use tf.compat.v1.ragged.RaggedTensorValue instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\harsh\\anaconda3\\Lib\\site-packages\\keras\\src\\engine\\base_layer_utils.py:384: The name tf.executing_eagerly_outside_functions is deprecated. Please use tf.compat.v1.executing_eagerly_outside_functions instead.\n",
      "\n",
      "91/91 [==============================] - 30s 309ms/step - loss: 0.1487 - accuracy: 0.9562 - val_loss: 6.0902e-05 - val_accuracy: 1.0000\n",
      "Epoch 2/25\n",
      "91/91 [==============================] - 18s 198ms/step - loss: 4.5641e-05 - accuracy: 1.0000 - val_loss: 1.7494e-05 - val_accuracy: 1.0000\n",
      "Epoch 3/25\n",
      "91/91 [==============================] - 18s 197ms/step - loss: 1.9626e-05 - accuracy: 1.0000 - val_loss: 1.3284e-05 - val_accuracy: 1.0000\n",
      "Epoch 4/25\n",
      "91/91 [==============================] - 18s 198ms/step - loss: 1.4195e-05 - accuracy: 1.0000 - val_loss: 1.0247e-05 - val_accuracy: 1.0000\n",
      "Epoch 5/25\n",
      "91/91 [==============================] - 18s 198ms/step - loss: 1.0363e-05 - accuracy: 1.0000 - val_loss: 7.5536e-06 - val_accuracy: 1.0000\n",
      "Epoch 6/25\n",
      "91/91 [==============================] - 18s 198ms/step - loss: 7.8180e-06 - accuracy: 1.0000 - val_loss: 6.0338e-06 - val_accuracy: 1.0000\n",
      "Epoch 7/25\n",
      "91/91 [==============================] - 18s 197ms/step - loss: 6.1500e-06 - accuracy: 1.0000 - val_loss: 5.4259e-06 - val_accuracy: 1.0000\n",
      "Epoch 8/25\n",
      "91/91 [==============================] - 18s 197ms/step - loss: 5.0390e-06 - accuracy: 1.0000 - val_loss: 4.5110e-06 - val_accuracy: 1.0000\n",
      "Epoch 9/25\n",
      "91/91 [==============================] - 18s 198ms/step - loss: 4.0964e-06 - accuracy: 1.0000 - val_loss: 3.9266e-06 - val_accuracy: 1.0000\n",
      "Epoch 10/25\n",
      "91/91 [==============================] - 18s 200ms/step - loss: 3.4706e-06 - accuracy: 1.0000 - val_loss: 3.2042e-06 - val_accuracy: 1.0000\n",
      "Epoch 11/25\n",
      "91/91 [==============================] - 18s 199ms/step - loss: 2.9226e-06 - accuracy: 1.0000 - val_loss: 2.9090e-06 - val_accuracy: 1.0000\n",
      "Epoch 12/25\n",
      "91/91 [==============================] - 18s 202ms/step - loss: 2.5053e-06 - accuracy: 1.0000 - val_loss: 2.4643e-06 - val_accuracy: 1.0000\n",
      "Epoch 13/25\n",
      "91/91 [==============================] - 18s 201ms/step - loss: 2.1153e-06 - accuracy: 1.0000 - val_loss: 1.9966e-06 - val_accuracy: 1.0000\n",
      "Epoch 14/25\n",
      "91/91 [==============================] - 19s 207ms/step - loss: 1.9782e-06 - accuracy: 1.0000 - val_loss: 1.9633e-06 - val_accuracy: 1.0000\n",
      "Epoch 15/25\n",
      "91/91 [==============================] - 18s 200ms/step - loss: 1.6492e-06 - accuracy: 1.0000 - val_loss: 1.9260e-06 - val_accuracy: 1.0000\n",
      "Epoch 16/25\n",
      "91/91 [==============================] - 18s 201ms/step - loss: 1.4669e-06 - accuracy: 1.0000 - val_loss: 1.7213e-06 - val_accuracy: 1.0000\n",
      "Epoch 17/25\n",
      "91/91 [==============================] - 18s 202ms/step - loss: 1.3126e-06 - accuracy: 1.0000 - val_loss: 1.8758e-06 - val_accuracy: 1.0000\n",
      "Epoch 18/25\n",
      "91/91 [==============================] - 19s 206ms/step - loss: 1.1666e-06 - accuracy: 1.0000 - val_loss: 1.7644e-06 - val_accuracy: 1.0000\n",
      "Epoch 19/25\n",
      "91/91 [==============================] - 19s 205ms/step - loss: 1.0475e-06 - accuracy: 1.0000 - val_loss: 1.3526e-06 - val_accuracy: 1.0000\n",
      "Epoch 20/25\n",
      "91/91 [==============================] - 18s 202ms/step - loss: 9.3406e-07 - accuracy: 1.0000 - val_loss: 1.1616e-06 - val_accuracy: 1.0000\n",
      "Epoch 21/25\n",
      "91/91 [==============================] - 18s 199ms/step - loss: 8.3305e-07 - accuracy: 1.0000 - val_loss: 1.1287e-06 - val_accuracy: 1.0000\n",
      "Epoch 22/25\n",
      "91/91 [==============================] - 18s 198ms/step - loss: 7.6342e-07 - accuracy: 1.0000 - val_loss: 1.1089e-06 - val_accuracy: 1.0000\n",
      "Epoch 23/25\n",
      "91/91 [==============================] - 18s 198ms/step - loss: 6.9261e-07 - accuracy: 1.0000 - val_loss: 8.8490e-07 - val_accuracy: 1.0000\n",
      "Epoch 24/25\n",
      "91/91 [==============================] - 18s 203ms/step - loss: 6.2422e-07 - accuracy: 1.0000 - val_loss: 9.3125e-07 - val_accuracy: 1.0000\n",
      "Epoch 25/25\n",
      "91/91 [==============================] - 18s 199ms/step - loss: 5.6868e-07 - accuracy: 1.0000 - val_loss: 8.2421e-07 - val_accuracy: 1.0000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x1d942bedb50>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D, MaxPooling2D, Flatten, Dense\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "\n",
    "classifier = Sequential()\n",
    "\n",
    "classifier.add(Conv2D(32, (3, 3), input_shape=(100, 100, 3), activation='relu'))\n",
    "\n",
    "\n",
    "classifier.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "classifier.add(Conv2D(32, (3, 3), activation='relu'))\n",
    "classifier.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "classifier.add(Flatten())\n",
    "\n",
    "\n",
    "classifier.add(Dense(units=128, activation='relu'))\n",
    "classifier.add(Dense(units=4, activation='softmax'))  \n",
    "\n",
    "classifier.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "\n",
    "\n",
    "classifier.fit_generator(\n",
    "    train_data,\n",
    "    steps_per_epoch=len(train_data),\n",
    "    epochs=25,\n",
    "    validation_data=test_data,\n",
    "    validation_steps=len(test_data))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8e3e6f65",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 140ms/step\n",
      "[[2.5964699e-08 7.3599908e-09 1.1152823e-12 1.0000000e+00]]\n",
      "Predicted class: sheath\n"
     ]
    }
   ],
   "source": [
    "from keras.preprocessing import image\n",
    "import numpy as np\n",
    "\n",
    "# Load the image you want to predict\n",
    "img_path = \"/Users/harsh/OneDrive/Desktop/paddy/sheath.jpg\"\n",
    "img = image.load_img(img_path, target_size=(100, 100))\n",
    "img_array = image.img_to_array(img)\n",
    "img_array = np.expand_dims(img_array, axis=0)  # Add batch dimension\n",
    "img_array /= 255.  # Rescale pixel values to [0, 1]\n",
    "\n",
    "# Make predictions\n",
    "predictions = classifier.predict(img_array)\n",
    "print(predictions)\n",
    "\n",
    "# Decode the predictions\n",
    "class_indices = train_data.class_indices\n",
    "reverse_indices = {v: k for k, v in class_indices.items()}\n",
    "predicted_class = reverse_indices[np.argmax(predictions)]\n",
    "print(\"Predicted class:\", predicted_class)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d6c1e1fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 28ms/step\n",
      "[[9.8829738e-15 1.5632965e-07 9.9999988e-01 2.1451611e-10]]\n",
      "Predicted class: brown leaf\n"
     ]
    }
   ],
   "source": [
    "from keras.preprocessing import image\n",
    "import numpy as np\n",
    "\n",
    "img_path = \"/Users/harsh/OneDrive/Desktop/paddy/test/brown leaf/brown leaf_0_64.jpeg\"\n",
    "img = image.load_img(img_path, target_size=(100, 100))\n",
    "img_array = image.img_to_array(img)\n",
    "img_array = np.expand_dims(img_array, axis=0)  \n",
    "img_array /= 255.  \n",
    "\n",
    "\n",
    "predictions = classifier.predict(img_array)\n",
    "print(predictions)\n",
    "\n",
    "\n",
    "class_indices = train_data.class_indices\n",
    "reverse_indices = {v: k for k, v in class_indices.items()}\n",
    "predicted_class = reverse_indices[np.argmax(predictions)]\n",
    "print(\"Predicted class:\", predicted_class)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "76625034",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 35ms/step\n",
      "[[1.0000000e+00 3.4413333e-11 5.7835381e-24 1.0856143e-11]]\n",
      "Predicted class: BLB\n"
     ]
    }
   ],
   "source": [
    "img_path = \"/Users/harsh/OneDrive/Desktop/paddy/BLB.jpg\"\n",
    "img = image.load_img(img_path, target_size=(100, 100))\n",
    "img_array = image.img_to_array(img)\n",
    "img_array = np.expand_dims(img_array, axis=0)  \n",
    "img_array /= 255.  \n",
    "\n",
    "\n",
    "predictions = classifier.predict(img_array)\n",
    "print(predictions)\n",
    "\n",
    "\n",
    "class_indices = train_data.class_indices\n",
    "reverse_indices = {v: k for k, v in class_indices.items()}\n",
    "predicted_class = reverse_indices[np.argmax(predictions)]\n",
    "print(\"Predicted class:\", predicted_class)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
